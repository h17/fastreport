{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound Event Detection with CNNs\n",
    "> ''\n",
    "\n",
    "- author: <a href=http://kozistr.tech/about>Hyeongchan Kim</a>\n",
    "- categories: [python, data science]\n",
    "- image:\n",
    "- permalink: /audio/\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent works have shown that using convolutional neural networks (CNNs) is powerful in various types of machine learning tasks like classification tasks across domains. CNN enables networks to catch informative features by fusing spatial and channel-wise information within local receptive fields at each layer. For audio signals, lots of related works take a spectrogram as input using CNN that allows extracting features both frequency and time wisely via its kernel, and these approaches show promising results.\n",
    "\n",
    "Unlike sound classification tasks, sound event detection (SED) is a task to detect the events in recorded audio, and it's crucial to find the various length of single or multiple events at a segment-level. Although CNN is a powerful method to extract its feature maps, it can't capture long time dependency in audio due to the limited sizes of the receptive field. To resolve this problem, we utilize both a gated recurrent unit (GRU) and a self-attention mechanism to handle long time dependency effectively.\n",
    "\n",
    "In this article, we'll explain the CNN architecture for detecting sound events by adopting the bi-GRU and self-attention module with the implementation and show performances compared with different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* introducing cornel birdcall dataset & task or in general purpose something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There're lots of feature extraction methods from the audio signal like *Spectrogram*, *MFCC*, and there're a few great libraries that allow us to use easily, for example, `librosa`. However, extracting these features from the signals takes a bit of time, especially for extracting features from tons of long audios. By the following, when extracting features and training a neural network, sometimes it becomes a bottleneck because of computation power.\n",
    "\n",
    "To resolve the issue, we utilize a library, [`torchlibrosa`](https://github.com/qiuqiangkong/torchlibrosa), PyTorch implementation of `librosa`. One of the advantages of using the library is it can run on **GPU**, faster than running on **CPU**.\n",
    "\n",
    "Here is a benchmark between running on GPU and CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To-Do : add a benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * To-Do : add an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "\n",
    "\n",
    "class AudioProcessing(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.spectrogram_extractor = Spectrogram(\n",
    "            n_fft=window_size,\n",
    "            hop_length=hop_size,\n",
    "            win_length=window_size,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True\n",
    "        )\n",
    "\n",
    "        self.logmel_extractor = LogmelFilterBank(\n",
    "            sr=sample_rate,\n",
    "            n_fft=window_size,\n",
    "            n_mels=mel_bins,\n",
    "            fmin=fmin,\n",
    "            fmax=fmax,\n",
    "            ref=ref,\n",
    "            amin=amin,\n",
    "            top_db=top_db,\n",
    "            freeze_parameters=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spectrogram_extractor(x)  # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)       # (batch_size, 1, time_steps, mel_bins)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* introducing related works on SED task like PANNs\n",
    "* introducing our architecture\n",
    "\n",
    "\n",
    "* explain why we chose / adopt this architecture\n",
    "* explain why this architecture works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Recipe is also the most crucial part of deep-learning. It also determines the performance of the architecture by optimizers, a learning rate scheduler, augmentations, etc.\n",
    "\n",
    "* augmentations\n",
    "* hyper-parameters\n",
    "* etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}