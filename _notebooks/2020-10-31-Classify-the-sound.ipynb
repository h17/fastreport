{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to classify a sound?\n",
    "> ''\n",
    "\n",
    "- author: <a href=http://kozistr.tech/about>Hyeongchan Kim</a>\n",
    "- categories: [python, data science]\n",
    "- image: images/yomex-owo-Bm7Vm8T4BQs-unsplash.jpg\n",
    "- permalink: /audio/\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tons of various sounds exist in our life. Starting from music that many of us usually listen to, lots of human voices, to the cry of endangered species like a bird. In some cases, it is crucial that classifying the source of the sounds and is already widely used for various purposes. Such as, there's a classifier for the genre of music in many music recommendation systems. Even ornithologists try to use a classifier to categorize which sounds of birds because it is hard to detect the birdcalls from the fields or noisy environments. Therefore, audio classifiers play a significant role in our lives.\n",
    "\n",
    "Recently, by the advance of the technologies, computation power is exponentially increased, so even doing heavy computation is possible in a millisecond like deep learning (DL). And it brings promising performance gain over the domains. It enables us to detect the categories more precisely than in the past. However, there's still an issue utilizing deep learning fast and accurately.\n",
    "\n",
    "In this post, We will use the birdcalls as an example and show how to deal with the data fast and detect the rare kind of birds using deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Recent works have shown that using convolutional neural networks (CNNs) is powerful in various types of machine learning tasks like classification tasks across domains. CNN enables networks to catch informative features by fusing spatial and channel-wise information within local receptive fields at each layer. For audio signals, lots of related works take a spectrogram as input using CNN that allows extracting features both frequency and time wisely via its kernel, and these approaches show promising results.\n",
    "Unlike sound classification tasks, sound event detection (SED) is a task to detect the events in recorded audio, and it's crucial to find the various length of single or multiple events at a segment-level. Although CNN is a powerful method to extract its feature maps, it can't capture long time dependency in audio due to the limited sizes of the receptive field. To resolve this problem, we utilize both a gated recurrent unit (GRU) and a self-attention mechanism to handle long time dependency effectively. In this article, we'll explain the CNN architecture for detecting sound events by adopting the bi-GRU and self-attention module with the implementation and show performances compared with different methods.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous post that `Tony` wrote, he explains well why and how we should process the audio data into *Spectrogram* to give to a deep learning model as an input. Continuing from the post, the speed of data processing is one of the keys to utilizing a deep learning model. Although the increment of computation power, the computation cost of audio processing is still expensive. However, if we choose a better computation resource to process the data like a Graphic Process Unit ([GPU](https://en.wikipedia.org/wiki/Graphics_processing_unit)), it can boost the speed of about ten to one hundred times faster!\n",
    "\n",
    "In this post, we will show how to process *Spectrogram* fast by utilizing a library called [`torchlibrosa`](https://github.com/qiuqiangkong/torchlibrosa) that enables us to process `Spectrogram` on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of extracting *Spectrogram* features using `torchlibrosa`. By implementing the `Spectrogram` algorithm into [`PyTorch`](https://pytorch.org/) which is a deep learning framework, it is able to run via a GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchlibrosa.stft import Spectrogram\n",
    "\n",
    "\n",
    "class AudioProcessing(nn.Module):\n",
    "    def __init__(self, window_size: int = 1024, hop_size: int = 320):\n",
    "        super().__init__()\n",
    "        self.spectrogram_extractor = Spectrogram(hop_length=hop_size, win_length=window_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.spectrogram_extractor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, deep learning also shows a brilliant performance in the audio domain. It can catch various patterns of target classes nicely in the time-series data. The more important thing is the environment and data matter in birdcalls. The environments like fields or the middle of the mountains, there are lots of noises interfering with the birdcalls. There are lots of birds that can exist in long recorded audio. So considering these cases, we need to build a noise-robust, multi-label classifier.\n",
    "\n",
    "We are going to introduce a deep learning architecture designed in Cornel Birdcall Identification Kaggle Challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
